# kubeadm-highavailiability - åŸºäºkubeadmçš„kubernetesé«˜å¯ç”¨é›†ç¾¤éƒ¨ç½²ï¼Œæ”¯æŒv1.9.xå’Œv1.7.xç‰ˆæœ¬ä»¥åŠv1.6.xç‰ˆæœ¬

![k8s logo](images/v1.6-v1.7/Kubernetes.png)

- [ä¸­æ–‡æ–‡æ¡£(for v1.9.xç‰ˆæœ¬)](README_CN.md)
- [English document(for v1.9.x version)](README.md)
- [ä¸­æ–‡æ–‡æ¡£(for v1.7.xç‰ˆæœ¬)](v1.6-v1.7/README_CN.md)
- [English document(for v1.7.x version)](v1.6-v1.7/README.md)
- [ä¸­æ–‡æ–‡æ¡£(for v1.6.xç‰ˆæœ¬)](v1.6-v1.7/README_v1.6.x_CN.md)
- [English document(for v1.6.x version)](v1.6-v1.7/README_v1.6.x.md)

---

- [GitHubé¡¹ç›®åœ°å€](https://github.com/cookeem/kubeadm-ha/)
- [OSChinaé¡¹ç›®åœ°å€](https://git.oschina.net/cookeem/kubeadm-ha/)

---

- è¯¥æŒ‡å¼•é€‚ç”¨äºv1.9.xç‰ˆæœ¬çš„kubernetesé›†ç¾¤

> v1.9.0ä»¥å‰çš„ç‰ˆæœ¬kubeadmè¿˜ä¸æ”¯æŒé«˜å¯ç”¨éƒ¨ç½²ï¼Œå› æ­¤ä¸æ¨èä½œä¸ºç”Ÿäº§ç¯å¢ƒçš„éƒ¨ç½²æ–¹å¼ã€‚ä»v1.9.xç‰ˆæœ¬å¼€å§‹ï¼Œkubeadmå®˜æ–¹æ­£å¼æ”¯æŒé«˜å¯ç”¨é›†ç¾¤çš„éƒ¨ç½²ï¼Œå®‰è£…kubeadmåŠ¡å¿…ä¿è¯ç‰ˆæœ¬è‡³å°‘ä¸º1.9.0ã€‚

### ç›®å½•

### ç›®å½•

1. [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
    1. [æ¦‚è¦éƒ¨ç½²æ¶æ„](#æ¦‚è¦éƒ¨ç½²æ¶æ„)
    1. [è¯¦ç»†éƒ¨ç½²æ¶æ„](#è¯¦ç»†éƒ¨ç½²æ¶æ„)
    1. [ä¸»æœºèŠ‚ç‚¹æ¸…å•](#ä¸»æœºèŠ‚ç‚¹æ¸…å•)
1. [å®‰è£…å‰å‡†å¤‡](#å®‰è£…å‰å‡†å¤‡)
    1. [ç‰ˆæœ¬ä¿¡æ¯](#ç‰ˆæœ¬ä¿¡æ¯)
    1. [æ‰€éœ€dockeré•œåƒ](#æ‰€éœ€dockeré•œåƒ)
    1. [ç³»ç»Ÿè®¾ç½®](#ç³»ç»Ÿè®¾ç½®)
1. [kuberneteså®‰è£…](#kuberneteså®‰è£…)
    1. [firewalldå’Œiptablesç›¸å…³ç«¯å£è®¾ç½®](#firewalldå’Œiptablesç›¸å…³ç«¯å£è®¾ç½®)
    1. [kubernetesç›¸å…³æœåŠ¡å®‰è£…](#kubernetesç›¸å…³æœåŠ¡å®‰è£…)
1. [é…ç½®æ–‡ä»¶åˆå§‹åŒ–](#é…ç½®æ–‡ä»¶åˆå§‹åŒ–)
    1. [åˆå§‹åŒ–è„šæœ¬é…ç½®](#åˆå§‹åŒ–è„šæœ¬é…ç½®) 
    1. [ç‹¬ç«‹etcdé›†ç¾¤éƒ¨ç½²](#ç‹¬ç«‹etcdé›†ç¾¤éƒ¨ç½²)
1. [ç¬¬ä¸€å°masteråˆå§‹åŒ–](#ç¬¬ä¸€å°masteråˆå§‹åŒ–)
    1. [kubeadmåˆå§‹åŒ–](#kubeadmåˆå§‹åŒ–)
    1. [å®‰è£…åŸºç¡€ç»„ä»¶](#å®‰è£…åŸºç¡€ç»„ä»¶)
1. [masteré›†ç¾¤é«˜å¯ç”¨è®¾ç½®](#masteré›†ç¾¤é«˜å¯ç”¨è®¾ç½®)
    1. [å¤åˆ¶é…ç½®](#å¤åˆ¶é…ç½®)
    1. [å…¶ä½™masterèŠ‚ç‚¹åˆå§‹åŒ–](#å…¶ä½™masterèŠ‚ç‚¹åˆå§‹åŒ–)
    1. [keepalivedå®‰è£…é…ç½®](#keepalivedå®‰è£…é…ç½®)
    1. [nginxè´Ÿè½½å‡è¡¡é…ç½®](#nginxè´Ÿè½½å‡è¡¡é…ç½®)
    1. [kube-proxyé…ç½®](#kube-proxyé…ç½®)
1. [nodeèŠ‚ç‚¹åŠ å…¥é«˜å¯ç”¨é›†ç¾¤è®¾ç½®](#nodeèŠ‚ç‚¹åŠ å…¥é«˜å¯ç”¨é›†ç¾¤è®¾ç½®)
    1. [kubeadmåŠ å…¥é«˜å¯ç”¨é›†ç¾¤](#kubeadmåŠ å…¥é«˜å¯ç”¨é›†ç¾¤)
    1. [éªŒè¯é›†ç¾¤é«˜å¯ç”¨è®¾ç½®](#éªŒè¯é›†ç¾¤é«˜å¯ç”¨è®¾ç½®)
    


### éƒ¨ç½²æ¶æ„

#### æ¦‚è¦éƒ¨ç½²æ¶æ„

![ha logo](images/v1.6-v1.7/ha.png)

* kubernetesé«˜å¯ç”¨çš„æ ¸å¿ƒæ¶æ„æ˜¯masterçš„é«˜å¯ç”¨ï¼Œkubectlã€å®¢æˆ·ç«¯ä»¥åŠnodesè®¿é—®load balancerå®ç°é«˜å¯ç”¨ã€‚

---
[è¿”å›ç›®å½•](#ç›®å½•)

#### è¯¦ç»†éƒ¨ç½²æ¶æ„

![k8s ha](images/v1.6-v1.7/k8s-ha.png)

* kubernetesç»„ä»¶è¯´æ˜

> kube-apiserverï¼šé›†ç¾¤æ ¸å¿ƒï¼Œé›†ç¾¤APIæ¥å£ã€é›†ç¾¤å„ä¸ªç»„ä»¶é€šä¿¡çš„ä¸­æ¢ï¼›é›†ç¾¤å®‰å…¨æ§åˆ¶ï¼›

> etcdï¼šé›†ç¾¤çš„æ•°æ®ä¸­å¿ƒï¼Œç”¨äºå­˜æ”¾é›†ç¾¤çš„é…ç½®ä»¥åŠçŠ¶æ€ä¿¡æ¯ï¼Œéå¸¸é‡è¦ï¼Œå¦‚æœæ•°æ®ä¸¢å¤±é‚£ä¹ˆé›†ç¾¤å°†æ— æ³•æ¢å¤ï¼›å› æ­¤é«˜å¯ç”¨é›†ç¾¤éƒ¨ç½²é¦–å…ˆå°±æ˜¯etcdæ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼›

> kube-schedulerï¼šé›†ç¾¤Podçš„è°ƒåº¦ä¸­å¿ƒï¼›é»˜è®¤kubeadmå®‰è£…æƒ…å†µä¸‹--leader-electå‚æ•°å·²ç»è®¾ç½®ä¸ºtrueï¼Œä¿è¯masteré›†ç¾¤ä¸­åªæœ‰ä¸€ä¸ªkube-schedulerå¤„äºæ´»è·ƒçŠ¶æ€ï¼›

> kube-controller-managerï¼šé›†ç¾¤çŠ¶æ€ç®¡ç†å™¨ï¼Œå½“é›†ç¾¤çŠ¶æ€ä¸æœŸæœ›ä¸åŒæ—¶ï¼Œkcmä¼šåŠªåŠ›è®©é›†ç¾¤æ¢å¤æœŸæœ›çŠ¶æ€ï¼Œæ¯”å¦‚ï¼šå½“ä¸€ä¸ªpodæ­»æ‰ï¼Œkcmä¼šåŠªåŠ›æ–°å»ºä¸€ä¸ªpodæ¥æ¢å¤å¯¹åº”replicas setæœŸæœ›çš„çŠ¶æ€ï¼›é»˜è®¤kubeadmå®‰è£…æƒ…å†µä¸‹--leader-electå‚æ•°å·²ç»è®¾ç½®ä¸ºtrueï¼Œä¿è¯masteré›†ç¾¤ä¸­åªæœ‰ä¸€ä¸ªkube-controller-managerå¤„äºæ´»è·ƒçŠ¶æ€ï¼›

> kubelet: kubernetes node agentï¼Œè´Ÿè´£ä¸nodeä¸Šçš„docker engineæ‰“äº¤é“ï¼›

> kube-proxy: æ¯ä¸ªnodeä¸Šä¸€ä¸ªï¼Œè´Ÿè´£service vipåˆ°endpoint podçš„æµé‡è½¬å‘ï¼Œå½“å‰ä¸»è¦é€šè¿‡è®¾ç½®iptablesè§„åˆ™å®ç°ã€‚

* è´Ÿè½½å‡è¡¡

> keepalivedé›†ç¾¤è®¾ç½®ä¸€ä¸ªè™šæ‹Ÿipåœ°å€ï¼Œè™šæ‹Ÿipåœ°å€æŒ‡å‘devops-master01ã€devops-master02ã€devops-master03ã€‚

> nginxç”¨äºdevops-master01ã€devops-master02ã€devops-master03çš„apiserverçš„è´Ÿè½½å‡è¡¡ã€‚å¤–éƒ¨kubectlä»¥åŠnodesè®¿é—®apiserverçš„æ—¶å€™å°±å¯ä»¥ç”¨è¿‡keepalivedçš„è™šæ‹Ÿip(192.168.20.10)ä»¥åŠnginxç«¯å£(16443)è®¿é—®masteré›†ç¾¤çš„apiserverã€‚

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### ä¸»æœºèŠ‚ç‚¹æ¸…å•

ä¸»æœºå | IPåœ°å€ | è¯´æ˜ | ç»„ä»¶ 
:--- | :--- | :--- | :---
devops-master01 ~ 03 | 192.168.20.27 ~ 29 | masterèŠ‚ç‚¹ * 3 | keepalivedã€nginxã€etcdã€kubeletã€kube-apiserverã€kube-schedulerã€kube-proxyã€kube-dashboardã€heapsterã€calico
æ—  | 192.168.20.10 | keepalivedè™šæ‹ŸIP | æ— 
devops-node01 ~ 04 | 192.168.20.17 ~ 20 | nodeèŠ‚ç‚¹ * 4 | kubeletã€kube-proxy

---

[è¿”å›ç›®å½•](#ç›®å½•)

### å®‰è£…å‰å‡†å¤‡

#### ç‰ˆæœ¬ä¿¡æ¯

* Linuxç‰ˆæœ¬ï¼šCentOS 7.4.1708
* å†…æ ¸ç‰ˆæœ¬: 4.6.4-1.el7.elrepo.x86_64


```
$ cat /etc/redhat-release 
CentOS Linux release 7.4.1708 (Core) 

$ uname -r
4.6.4-1.el7.elrepo.x86_64
```

* dockerç‰ˆæœ¬ï¼š17.12.0-ce-rc2

```
$ docker version
Client:
 Version:   17.12.0-ce-rc2
 API version:   1.35
 Go version:    go1.9.2
 Git commit:    f9cde63
 Built: Tue Dec 12 06:42:20 2017
 OS/Arch:   linux/amd64

Server:
 Engine:
  Version:  17.12.0-ce-rc2
  API version:  1.35 (minimum version 1.12)
  Go version:   go1.9.2
  Git commit:   f9cde63
  Built:    Tue Dec 12 06:44:50 2017
  OS/Arch:  linux/amd64
  Experimental: false
```

* kubeadmç‰ˆæœ¬ï¼šv1.9.3

```
$ kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"9", GitVersion:"v1.9.3", GitCommit:"d2835416544f298c919e2ead3be3d0864b52323b", GitTreeState:"clean", BuildDate:"2018-02-07T11:55:20Z", GoVersion:"go1.9.2", Compiler:"gc", Platform:"linux/amd64"}
```

* kubeletç‰ˆæœ¬ï¼šv1.9.3

```
$ kubelet --version
Kubernetes v1.9.3
```

* ç½‘ç»œç»„ä»¶

> canal (flannel + calico)

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### æ‰€éœ€dockeré•œåƒ

* ç›¸å…³dockeré•œåƒä»¥åŠç‰ˆæœ¬

```
$ docker pull quay.io/calico/kube-controllers:v2.0.0
$ docker pull quay.io/calico/node:v3.0.1
$ docker pull quay.io/calico/cni:v2.0.0
$ docker pull quay.io/coreos/flannel:v0.9.1-amd64
$ docker pull gcr.io/google_containers/heapster-amd64:v1.4.2
$ docker pull gcr.io/google_containers/heapster-grafana-amd64:v4.4.3
$ docker pull gcr.io/google_containers/heapster-influxdb-amd64:v1.3.3
$ docker pull gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.7
$ docker pull gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7
$ docker pull gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.7
$ docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.1
$ docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.1
$ docker pull gcr.io/google_containers/kube-proxy-amd64:v1.9.1
$ docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.1
$ docker pull gcr.io/google_containers/kubernetes-dashboard-amd64:v1.8.1
$ docker pull nginx
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### ç³»ç»Ÿè®¾ç½®

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šå¢åŠ kubernetesä»“åº“ 

```
$ cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè¿›è¡Œç³»ç»Ÿæ›´æ–°

```
$ yum update -y
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šå…³é—­é˜²ç«å¢™

```
$ systemctl disable firewalld && systemctl stop firewalld && systemctl status firewalld
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®SELINUXä¸ºpermissiveæ¨¡å¼

```
$ vi /etc/selinux/config
SELINUX=permissive

$ setenforce 0
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®iptableså‚æ•°ï¼Œå¦åˆ™kubeadm initä¼šæç¤ºé”™è¯¯

```
$ cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sysctl --system
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šç¦ç”¨swap

```
$ swapoff -a

# ç¦ç”¨fstabä¸­çš„swapé¡¹ç›®
$ vi /etc/fstab
#/dev/mapper/centos-swap swap                    swap    defaults        0 0

# ç¡®è®¤swapå·²ç»è¢«ç¦ç”¨
$ cat /proc/swaps
Filename                Type        Size    Used    Priority
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šé‡å¯ä¸»æœº

```
$ reboot
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### kuberneteså®‰è£…

#### firewalldå’Œiptablesç›¸å…³ç«¯å£è®¾ç½®

- ç›¸å…³ç«¯å£ï¼ˆmasterï¼‰

åè®® | æ–¹å‘ | ç«¯å£ | è¯´æ˜
:--- | :--- | :--- | :---
TCP | Inbound | 16443*    | Load balancer Kubernetes API server port
TCP | Inbound | 6443*     | Kubernetes API server
TCP | Inbound | 2379-2380 | etcd server client API
TCP | Inbound | 10250     | Kubelet API
TCP | Inbound | 10251     | kube-scheduler
TCP | Inbound | 10252     | kube-controller-manager
TCP | Inbound | 10255     | Read-only Kubelet API

- ç›¸å…³ç«¯å£ï¼ˆworkerï¼‰

åè®® | æ–¹å‘ | ç«¯å£ | è¯´æ˜
:--- | :--- | :--- | :---
TCP | Inbound | 10250       | Kubelet API
TCP | Inbound | 10255       | Read-only Kubelet API
TCP | Inbound | 30000-32767 | NodePort Services**

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### kubernetesç›¸å…³æœåŠ¡å®‰è£…

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸ŠéªŒè¯SELINUXæ¨¡å¼ï¼Œå¿…é¡»ä¿è¯SELINUXä¸ºpermissiveæ¨¡å¼ï¼Œå¦åˆ™kuberneteså¯åŠ¨ä¼šå‡ºç°å„ç§å¼‚å¸¸

```
$ getenforce
Permissive
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šå®‰è£…å¹¶å¯åŠ¨kubernetes 

```
$ yum install -y docker-ce-17.12.0.ce-0.2.rc2.el7.centos.x86_64
$ yum install -y docker-compose-1.9.0-5.el7.noarch
$ systemctl enable docker && systemctl start docker

$ yum install -y kubelet-1.9.1-0.x86_64 kubeadm-1.9.1-0.x86_64 kubectl-1.9.1-0.x86_64
$ systemctl enable kubelet && systemctl start kubelet
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®kubeletä½¿ç”¨cgroupfsï¼Œä¸dockerdä¿æŒä¸€è‡´ï¼Œå¦åˆ™kubeletä¼šå¯åŠ¨æŠ¥é”™

```
# é»˜è®¤kubeletä½¿ç”¨çš„cgroup-driver=systemdï¼Œæ”¹ä¸ºcgroup-driver=cgroupfs
$ vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
#Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=systemd"
Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs"

# é‡è®¾kubeletæœåŠ¡ï¼Œå¹¶é‡å¯kubeletæœåŠ¡
$ systemctl daemon-reload && systemctl restart kubelet
```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šå®‰è£…å¹¶å¯åŠ¨keepalived

```
$ yum install -y keepalived
$ systemctl enable keepalived && systemctl restart keepalived
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### é…ç½®æ–‡ä»¶åˆå§‹åŒ–

#### åˆå§‹åŒ–è„šæœ¬é…ç½®

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè·å–ä»£ç ï¼Œå¹¶è¿›å…¥ä»£ç ç›®å½•

```
$ git clone https://github.com/cookeem/kubeadm-ha

$ cd kubeadm-ha
```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè®¾ç½®åˆå§‹åŒ–è„šæœ¬é…ç½®ï¼Œæ¯ä¸€é¡¹é…ç½®å‚è§è„šæœ¬ä¸­çš„é…ç½®è¯´æ˜ï¼Œè¯·åŠ¡å¿…æ­£ç¡®é…ç½®ã€‚è¯¥è„šæœ¬ç”¨äºç”Ÿæˆç›¸å…³é‡è¦çš„é…ç½®æ–‡ä»¶

```
$ vi create-config.sh

# local machine ip address
export K8SHA_IPLOCAL=192.168.20.27

# local machine etcd name, options: etcd1, etcd2, etcd3
export K8SHA_ETCDNAME=etcd1

# local machine keepalived state config, options: MASTER, BACKUP. One keepalived cluster only one MASTER, other's are BACKUP
export K8SHA_KA_STATE=MASTER

# local machine keepalived priority config, options: 102, 101, 100. MASTER must 102
export K8SHA_KA_PRIO=102

# local machine keepalived network interface name config, for example: eth0
export K8SHA_KA_INTF=nm-bond

#######################################
# all masters settings below must be same
#######################################

# master keepalived virtual ip address
export K8SHA_IPVIRTUAL=192.168.20.10

# master01 ip address
export K8SHA_IP1=192.168.20.27

# master02 ip address
export K8SHA_IP2=192.168.20.28

# master03 ip address
export K8SHA_IP3=192.168.20.29

# master01 hostname
export K8SHA_HOSTNAME1=devops-master01

# master02 hostname
export K8SHA_HOSTNAME2=devops-master02

# master03 hostname
export K8SHA_HOSTNAME3=devops-master03

# keepalived auth_pass config, all masters must be same
export K8SHA_KA_AUTH=4cdf7dc3b4c90194d1600c483e10ad1d

# kubernetes cluster token, you can use 'kubeadm token generate' to get a new one
export K8SHA_TOKEN=7f276c.0741d82a5337f526

# kubernetes CIDR pod subnet, if CIDR pod subnet is "10.244.0.0/16" please set to "10.244.0.0\\/16"
export K8SHA_CIDR=10.244.0.0\\/16

# calico network settings, set a reachable ip address for the cluster network interface, for example you can use the gateway ip address
export K8SHA_CALICO_REACHABLE_IP=192.168.20.1
```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè¿è¡Œé…ç½®è„šæœ¬ï¼Œåˆ›å»ºå¯¹åº”çš„é…ç½®æ–‡ä»¶ï¼Œé…ç½®æ–‡ä»¶åŒ…æ‹¬:

> etcdé›†ç¾¤docker-compose.yamlæ–‡ä»¶

> keepalivedé…ç½®æ–‡ä»¶

> nginxè´Ÿè½½å‡è¡¡é›†ç¾¤docker-compose.yamlæ–‡ä»¶

> kubeadm init é…ç½®æ–‡ä»¶

> calicoé…ç½®æ–‡ä»¶

```
$ ./create-config.sh
set etcd cluster docker-compose.yaml file success: etcd/docker-compose.yaml
set keepalived config file success: /etc/keepalived/keepalived.conf
set nginx load balancer config file success: nginx-lb/nginx-lb.conf
set kubeadm init config file success: kubeadm-init.yaml
set calico deployment config file success: kube-calico/calico.yaml
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### ç‹¬ç«‹etcdé›†ç¾¤éƒ¨ç½²

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šé‡ç½®å¹¶å¯åŠ¨etcdé›†ç¾¤ï¼ˆéTLSæ¨¡å¼ï¼‰

```
# é‡ç½®kubernetesé›†ç¾¤
$ kubeadm reset

# æ¸…ç©ºetcdé›†ç¾¤æ•°æ®
$ rm -rf /var/lib/etcd-cluster

# é‡ç½®å¹¶å¯åŠ¨etcdé›†ç¾¤
$ docker-compose --file etcd/docker-compose.yaml stop
$ docker-compose --file etcd/docker-compose.yaml rm -f
$ docker-compose --file etcd/docker-compose.yaml up -d

# éªŒè¯etcdé›†ç¾¤çŠ¶æ€æ˜¯å¦æ­£å¸¸

$ docker exec -ti etcd etcdctl cluster-health
member 531504c79088f553 is healthy: got healthy result from http://192.168.20.29:2379
member 56c53113d5e1cfa3 is healthy: got healthy result from http://192.168.20.27:2379
member 7026e604579e4d64 is healthy: got healthy result from http://192.168.20.28:2379
cluster is healthy

$ docker exec -ti etcd etcdctl member list
531504c79088f553: name=etcd3 peerURLs=http://192.168.20.29:2380 clientURLs=http://192.168.20.29:2379,http://192.168.20.29:4001 isLeader=false
56c53113d5e1cfa3: name=etcd1 peerURLs=http://192.168.20.27:2380 clientURLs=http://192.168.20.27:2379,http://192.168.20.27:4001 isLeader=false
7026e604579e4d64: name=etcd2 peerURLs=http://192.168.20.28:2380 clientURLs=http://192.168.20.28:2379,http://192.168.20.28:4001 isLeader=true
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### ç¬¬ä¸€å°masteråˆå§‹åŒ–

#### kubeadmåˆå§‹åŒ–

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šé‡ç½®ç½‘ç»œ

```
$ systemctl stop kubelet
$ systemctl stop docker
$ rm -rf /var/lib/cni/
$ rm -rf /var/lib/kubelet/*
$ rm -rf /etc/cni/

# åˆ é™¤é—ç•™çš„ç½‘ç»œæ¥å£
$ ip a | grep -E 'docker|flannel|cni'
$ ip link del docker0
$ ip link del flannel.1
$ ip link del cni0

$ systemctl restart docker && systemctl restart kubelet
$ ip a | grep -E 'docker|flannel|cni'
```

* åœ¨devops-master01ä¸Šè¿›è¡Œåˆå§‹åŒ–ï¼Œæ³¨æ„ï¼ŒåŠ¡å¿…æŠŠè¾“å‡ºçš„kubeadm join --token XXX --discovery-token-ca-cert-hash YYY ä¿¡æ¯è®°å½•ä¸‹æ¥ï¼Œåç»­æ“ä½œéœ€è¦ç”¨åˆ°

```
$ kubeadm init --config=kubeadm-init.yaml
...
  kubeadm join --token 7f276c.0741d82a5337f526 192.168.20.27:6443 --discovery-token-ca-cert-hash sha256:a4a1eaf725a0fc67c3028b3063b92e6af7f2eb0f4ae028f12b3415a6fd2d2a5e
```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè®¾ç½®kubectlå®¢æˆ·ç«¯è¿æ¥

```
$ vi ~/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf

$ source ~/.bashrc
```

#### å®‰è£…åŸºç¡€ç»„ä»¶

* åœ¨devops-master01ä¸Šå®‰è£…flannelç½‘ç»œç»„ä»¶

```
# æ²¡æœ‰ç½‘ç»œç»„ä»¶çš„æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹çŠ¶æ€æ˜¯ä¸æ­£å¸¸çš„
$ kubectl get node
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   NotReady  master    14s       v1.9.1

# å®‰è£…flannelç½‘ç»œç»„ä»¶
$ kubectl apply -f kube-flannel/
clusterrole "flannel" created
clusterrolebinding "flannel" created
serviceaccount "flannel" created
configmap "kube-flannel-cfg" created
daemonset "kube-flannel-ds" created

# ç­‰å¾…æ‰€æœ‰podsæ­£å¸¸
$ kubectl get pods --all-namespaces -o wide -w
```

* åœ¨devops-master01ä¸Šå®‰è£…calicoç½‘ç»œç»„ä»¶

```
# è®¾ç½®masterèŠ‚ç‚¹ä¸ºschedulable
$ kubectl taint nodes --all node-role.kubernetes.io/master-

# å®‰è£…calicoç½‘ç»œç»„ä»¶
$ kubectl apply -f kube-calico/
configmap "calico-config" created
secret "calico-etcd-secrets" created
daemonset "calico-node" created
deployment "calico-kube-controllers" created
serviceaccount "calico-kube-controllers" created
serviceaccount "calico-node" created
clusterrole "calico-kube-controllers" created
clusterrolebinding "calico-kube-controllers" created
clusterrole "calico-node" created
clusterrolebinding "calico-node" created
```

* åœ¨devops-master01ä¸Šå®‰è£…dashboard

```
$ kubectl apply -f kube-dashboard/
serviceaccount "admin-user" created
clusterrolebinding "admin-user" created
secret "kubernetes-dashboard-certs" created
serviceaccount "kubernetes-dashboard" created
role "kubernetes-dashboard-minimal" created
rolebinding "kubernetes-dashboard-minimal" created
deployment "kubernetes-dashboard" created
service "kubernetes-dashboard" created

$ kubectl get pods --all-namespaces
NAMESPACE       NAME                                        READY     STATUS    RESTARTS   AGE
kube-system     calico-kube-controllers-7749c84f4-p8c4d     1/1       Running   0          3m
kube-system     calico-node-2jlwj                           2/2       Running   6          13m
kube-system     kube-apiserver-devops-master01              1/1       Running   6          5m
kube-system     kube-controller-manager-devops-master01     1/1       Running   8          5m
kube-system     kube-dns-6f4fd4bdf-8jnpc                    3/3       Running   3          4m
kube-system     kube-flannel-ds-2fgsw                       1/1       Running   8          14m
kube-system     kube-proxy-7rh8x                            1/1       Running   3          13m
kube-system     kube-scheduler-devops-master01              1/1       Running   8          5m
kube-system     kubernetes-dashboard-87497878f-p6nj4        1/1       Running   0          4m
```

* é€šè¿‡æµè§ˆå™¨è®¿é—®dashboardåœ°å€

> https://devops-master01:30000/#!/login

* dashboardç™»å½•é¡µé¢æ•ˆæœå¦‚ä¸‹å›¾

![dashboard-login](images/dashboard-login.png)

* è·å–tokenï¼ŒæŠŠtokenç²˜è´´åˆ°loginé¡µé¢çš„tokenä¸­ï¼Œå³å¯è¿›å…¥dashboard

```
$ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')
```

![dashboard](images/dashboard.png)

* åœ¨devops-master01ä¸Šå®‰è£…heapster

```
$ kubectl apply -f kube-heapster/influxdb/
service "monitoring-grafana" created
serviceaccount "heapster" created
deployment "heapster" created
service "heapster" created
deployment "monitoring-influxdb" created
service "monitoring-influxdb" created

$ kubectl apply -f kube-heapster/rbac/
clusterrolebinding "heapster" created

$ kubectl get pods --all-namespaces 
NAME                                      READY     STATUS        RESTARTS   AGE
calico-kube-controllers-7749c84f4-p8c4d   1/1       Running       0          8m
calico-node-2jlwj                         2/2       Running       6          13d
heapster-698c5f45bd-wnv6x                 1/1       Running       0          1m
kube-apiserver-devops-master01            1/1       Running       6          5d
kube-controller-manager-devops-master01   1/1       Running       8          5d
kube-dns-6f4fd4bdf-8jnpc                  3/3       Running       3          4h
kube-flannel-ds-2fgsw                     1/1       Running       8          14d
kube-proxy-7rh8x                          1/1       Running       3          13d
kube-scheduler-devops-master01            1/1       Running       8          5d
kubernetes-dashboard-87497878f-p6nj4      1/1       Running       0          4h
monitoring-grafana-5ffb49ff84-xxwzn       1/1       Running       0          1m
monitoring-influxdb-5b77d47fdd-wd7xm      1/1       Running       0          1m

# ç­‰å¾…5åˆ†é’Ÿ
kubectl top pod --all-namespaces
NAMESPACE     NAME                                      CPU(cores)   MEMORY(bytes)   
kube-system   calico-kube-controllers-d987c6db5-zjxnv   0m           20Mi            
kube-system   calico-node-hmdlg                         16m          83Mi            
kube-system   heapster-dfd674df9-hct67                  1m           24Mi            
kube-system   kube-apiserver-devops-master01            24m          240Mi           
kube-system   kube-controller-manager-devops-master01   14m          50Mi            
kube-system   kube-dns-6f4fd4bdf-zg66x                  1m           49Mi            
kube-system   kube-flannel-ds-h7ng4                     6m           33Mi            
kube-system   kube-proxy-mxcwz                          2m           29Mi            
kube-system   kube-scheduler-devops-master01            5m           22Mi            
kube-system   kubernetes-dashboard-7b7b5cd79b-6ldfn     0m           20Mi            
kube-system   monitoring-grafana-76848b566c-h5998       0m           28Mi            
kube-system   monitoring-influxdb-6c4b84d695-whzmp      1m           24Mi            
```

* è®¿é—®dashboardåœ°å€ï¼Œç­‰10åˆ†é’Ÿï¼Œå°±ä¼šæ˜¾ç¤ºæ€§èƒ½æ•°æ®

> https://devops-master01:30000/#!/login

![heapster-dashboard](images/heapster-dashboard.png)

![heapster](images/heapster.png)

* è‡³æ­¤ï¼Œç¬¬ä¸€å°masteræˆåŠŸå®‰è£…ï¼Œå¹¶å·²ç»å®Œæˆflannelã€calicoã€dashboardã€heapsterçš„éƒ¨ç½²

---

[è¿”å›ç›®å½•](#ç›®å½•)

### masteré›†ç¾¤é«˜å¯ç”¨è®¾ç½®

#### å¤åˆ¶é…ç½®

* åœ¨devops-master01ä¸Šå¤åˆ¶ç›®å½•/etc/kubernetes/pkiåˆ°devops-master02ã€devops-master03ï¼Œä»v1.9.xå¼€å§‹ï¼Œkubeadmä¼šæ£€æµ‹pkiç›®å½•æ˜¯å¦æœ‰è¯ä¹¦ï¼Œå¦‚æœå·²ç»å­˜åœ¨è¯ä¹¦åˆ™è·³è¿‡è¯ä¹¦ç”Ÿæˆçš„æ­¥éª¤

```
scp -r /etc/kubernetes/pki devops-master02:/etc/kubernetes/

scp -r /etc/kubernetes/pki devops-master03:/etc/kubernetes/
```

---
[è¿”å›ç›®å½•](#ç›®å½•)

#### å…¶ä½™masterèŠ‚ç‚¹åˆå§‹åŒ–

* åœ¨devops-master02è¿›è¡Œåˆå§‹åŒ–

```
# è¾“å‡ºçš„tokenå’Œdiscovery-token-ca-cert-hashåº”è¯¥ä¸devops-master01ä¸Šçš„å®Œå…¨ä¸€è‡´
$ kubeadm init --config=kubeadm-init.yaml
...
  kubeadm join --token 7f276c.0741d82a5337f526 192.168.20.28:6443 --discovery-token-ca-cert-hash sha256:a4a1eaf725a0fc67c3028b3063b92e6af7f2eb0f4ae028f12b3415a6fd2d2a5e
```

* åœ¨devops-master03è¿›è¡Œåˆå§‹åŒ–

```
# è¾“å‡ºçš„tokenå’Œdiscovery-token-ca-cert-hashåº”è¯¥ä¸devops-master01ä¸Šçš„å®Œå…¨ä¸€è‡´
$ kubeadm init --config=kubeadm-init.yaml
...
  kubeadm join --token 7f276c.0741d82a5337f526 192.168.20.29:6443 --discovery-token-ca-cert-hash sha256:a4a1eaf725a0fc67c3028b3063b92e6af7f2eb0f4ae028f12b3415a6fd2d2a5e
```

* åœ¨devops-master01ä¸Šæ£€æŸ¥nodesåŠ å…¥æƒ…å†µ

```
$ kubectl get nodes
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   Ready     master    19m       v1.9.1
devops-master02   Ready     master    4m        v1.9.1
devops-master03   Ready     master    4m        v1.9.1
```

* åœ¨æ‰€æœ‰masterä¸Šå¢åŠ apiserverçš„apiserver-countè®¾ç½®

```
$ vi /etc/kubernetes/manifests/kube-apiserver.yaml
    - --apiserver-count=3

# é‡å¯æœåŠ¡
$ systemctl restart docker && systemctl restart kubelet
```

* åœ¨devops-master01ä¸Šæ£€æŸ¥é«˜å¯ç”¨çŠ¶æ€

```
$ kubectl get pods --all-namespaces -o wide
NAMESPACE     NAME                                      READY     STATUS    RESTARTS   AGE       IP              NODE
kube-system   calico-kube-controllers-d987c6db5-zjxnv   1/1       Running   2          14m       192.168.20.27   devops-master01
kube-system   calico-node-dldxz                         2/2       Running   2          3m        192.168.20.29   devops-master03
kube-system   calico-node-hmdlg                         2/2       Running   4          14m       192.168.20.27   devops-master01
kube-system   calico-node-tkbbx                         2/2       Running   2          3m        192.168.20.28   devops-master02
kube-system   heapster-dfd674df9-hct67                  1/1       Running   2          11m       10.244.172.11   devops-master01
kube-system   kube-apiserver-devops-master01            1/1       Running   1          2m        192.168.20.27   devops-master01
kube-system   kube-apiserver-devops-master02            1/1       Running   1          2m        192.168.20.28   devops-master02
kube-system   kube-apiserver-devops-master03            1/1       Running   0          24s       192.168.20.29   devops-master03
kube-system   kube-controller-manager-devops-master01   1/1       Running   2          15m       192.168.20.27   devops-master01
kube-system   kube-controller-manager-devops-master02   1/1       Running   1          2m        192.168.20.28   devops-master02
kube-system   kube-controller-manager-devops-master03   1/1       Running   1          2m        192.168.20.29   devops-master03
kube-system   kube-dns-6f4fd4bdf-zg66x                  3/3       Running   6          16m       10.244.172.13   devops-master01
kube-system   kube-flannel-ds-6njgf                     1/1       Running   1          3m        192.168.20.29   devops-master03
kube-system   kube-flannel-ds-g24ww                     1/1       Running   1          3m        192.168.20.28   devops-master02
kube-system   kube-flannel-ds-h7ng4                     1/1       Running   2          16m       192.168.20.27   devops-master01
kube-system   kube-proxy-2kk8s                          1/1       Running   1          3m        192.168.20.28   devops-master02
kube-system   kube-proxy-mxcwz                          1/1       Running   2          16m       192.168.20.27   devops-master01
kube-system   kube-proxy-vz7nf                          1/1       Running   1          3m        192.168.20.29   devops-master03
kube-system   kube-scheduler-devops-master01            1/1       Running   2          16m       192.168.20.27   devops-master01
kube-system   kube-scheduler-devops-master02            1/1       Running   1          2m        192.168.20.28   devops-master02
kube-system   kube-scheduler-devops-master03            1/1       Running   1          2m        192.168.20.29   devops-master03
kube-system   kubernetes-dashboard-7b7b5cd79b-6ldfn     1/1       Running   3          12m       10.244.172.12   devops-master01
kube-system   monitoring-grafana-76848b566c-h5998       1/1       Running   2          11m       10.244.172.14   devops-master01
kube-system   monitoring-influxdb-6c4b84d695-whzmp      1/1       Running   2          11m       10.244.172.10   devops-master01
```

* è®¾ç½®æ‰€æœ‰masterçš„scheduable

```
$ kubectl taint nodes --all node-role.kubernetes.io/master-
node "devops-master02" untainted
node "devops-master03" untainted
```

* å¯¹åŸºç¡€ç»„ä»¶è¿›è¡Œå¤šèŠ‚ç‚¹scale

```
$ kubectl get deploy -n kube-system
NAME                      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
calico-kube-controllers   1         1         1            1           14d
heapster                  1         1         1            0           8m
kube-dns                  3         3         3            3           14d
kubernetes-dashboard      1         1         1            1           14d
monitoring-grafana        1         1         1            0           8m
monitoring-influxdb       1         1         1            0           8m

# calicoæ”¯æŒå¤šèŠ‚ç‚¹
$ kubectl scale --replicas=3 -n kube-system deployment/calico-kube-controllers
$ kubectl get pods --all-namespaces -o wide| grep calico-kube-controllers

# dnsæ”¯æŒå¤šèŠ‚ç‚¹
$ kubectl scale --replicas=3 -n kube-system deployment/kube-dns
$ kubectl get pods --all-namespaces -o wide| grep kube-dns

# dashboardæ”¯æŒå¤šèŠ‚ç‚¹
$ kubectl scale --replicas=3 -n kube-system deployment/kubernetes-dashboard
$ kubectl get pods --all-namespaces -o wide| grep kubernetes-dashboard

# heapsterå¯åŠ¨å¤šä¸ªå°±ä¼šå‡ºç°é—®é¢˜ï¼Œè¯·ä¸è¦å¯åŠ¨å¤šä¸ª
```

```
kubectl get nodes
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   Ready     master    38m       v1.9.1
devops-master02   Ready     master    25m       v1.9.1
devops-master03   Ready     master    25m       v1.9.1
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### keepalivedå®‰è£…é…ç½®

* åœ¨masterä¸Šå®‰è£…keepalived

```
$ systemctl restart keepalived

$ ping 192.168.20.10
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### nginxè´Ÿè½½å‡è¡¡é…ç½®

* åœ¨masterä¸Šå®‰è£…å¹¶å¯åŠ¨nginxä½œä¸ºè´Ÿè½½å‡è¡¡

```
$ docker-compose -f nginx-lb/docker-compose.yaml up -d
```

* åœ¨masterä¸ŠéªŒè¯è´Ÿè½½å‡è¡¡å’Œkeepalivedæ˜¯å¦æˆåŠŸ

```
curl -k 192.168.20.10:16443 | wc -l
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    14    0    14    0     0   3958      0 --:--:-- --:--:-- --:--:-- 14000
1
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### kube-proxyé…ç½®

- åœ¨devops-master01ä¸Šè®¾ç½®proxyé«˜å¯ç”¨ï¼Œè®¾ç½®serveræŒ‡å‘é«˜å¯ç”¨è™šæ‹ŸIPä»¥åŠè´Ÿè½½å‡è¡¡çš„16443ç«¯å£
```
$ kubectl edit -n kube-system configmap/kube-proxy
        server: https://192.168.20.10:16443
```

- åœ¨masterä¸Šé‡å¯proxy

```
$ kubectl get pods --all-namespaces -o wide | grep proxy

$ kubectl delete pod -n kube-system kube-proxy-XXX
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### nodeèŠ‚ç‚¹åŠ å…¥é«˜å¯ç”¨é›†ç¾¤è®¾ç½®

#### kubeadmåŠ å…¥é«˜å¯ç”¨é›†ç¾¤

- åœ¨æ‰€æœ‰workerèŠ‚ç‚¹ä¸Šè¿›è¡ŒåŠ å…¥kubernetesé›†ç¾¤æ“ä½œï¼Œè¿™é‡Œç»Ÿä¸€ä½¿ç”¨devops-master01çš„apiserveråœ°å€æ¥åŠ å…¥é›†ç¾¤ 

```
$ kubeadm join --token 7f276c.0741d82a5337f526 192.168.20.27:6443 --discovery-token-ca-cert-hash sha256:a4a1eaf725a0fc67c3028b3063b92e6af7f2eb0f4ae028f12b3415a6fd2d2a5e
```

- åœ¨æ‰€æœ‰workerèŠ‚ç‚¹ä¸Šä¿®æ”¹kubernetesé›†ç¾¤è®¾ç½®ï¼Œæ›´æ”¹serverä¸ºé«˜å¯ç”¨è™šæ‹ŸIPä»¥åŠè´Ÿè½½å‡è¡¡çš„16443ç«¯å£

```
sed -e "s/192.168.20.27:6443/192.168.20.10:16443/g" /etc/kubernetes/bootstrap-kubelet.conf > /etc/kubernetes/bootstrap-kubelet.conf

systemctl restart docker && systemctl restart kubelet
```


```
kubectl get nodes
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   Ready     master    46m       v1.9.1
devops-master02   Ready     master    44m       v1.9.1
devops-master03   Ready     master    44m       v1.9.1
devops-node01     Ready     <none>    50s       v1.9.1
devops-node02     Ready     <none>    26s       v1.9.1
devops-node03     Ready     <none>    22s       v1.9.1
devops-node04     Ready     <none>    17s       v1.9.1
```

- è®¾ç½®workersçš„èŠ‚ç‚¹æ ‡ç­¾

```
kubectl label nodes devops-node01 role=worker
kubectl label nodes devops-node02 role=worker
kubectl label nodes devops-node03 role=worker
kubectl label nodes devops-node04 role=worker
```

#### éªŒè¯é›†ç¾¤é«˜å¯ç”¨è®¾ç½®

```
# åˆ›å»ºä¸€ä¸ªreplicas=3çš„nginx deployment
$ kubectl run nginx --image=nginx --replicas=3 --port=80
deployment "nginx" created

# æ£€æŸ¥nginx podçš„åˆ›å»ºæƒ…å†µ
$ kubectl get pods -l=run=nginx -o wide
NAME                     READY     STATUS    RESTARTS   AGE       IP              NODE
nginx-6c7c8978f5-558kd   1/1       Running   0          9m        10.244.77.217   devops-node03
nginx-6c7c8978f5-ft2z5   1/1       Running   0          9m        10.244.172.67   devops-master01
nginx-6c7c8978f5-jr29b   1/1       Running   0          9m        10.244.85.165   devops-node04

# åˆ›å»ºnginxçš„NodePort service
$ kubectl expose deployment nginx --type=NodePort --port=80
service "nginx" exposed

# æ£€æŸ¥nginx serviceçš„åˆ›å»ºæƒ…å†µ
$ kubectl get svc -l=run=nginx -o wide
NAME      TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE       SELECTOR
nginx     NodePort   10.101.144.192   <none>        80:30847/TCP   10m       run=nginx

# æ£€æŸ¥nginx NodePort serviceæ˜¯å¦æ­£å¸¸æä¾›æœåŠ¡
$ curl devops-master01:30847
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

- è‡³æ­¤kubernetesé«˜å¯ç”¨é›†ç¾¤å®Œæˆéƒ¨ç½²ğŸ˜ƒ
